#!/usr/bin/python

# This script uses reddit_api to fetch posts and comments from reddit.com.
# When it finds a link to a website that requires javascript to view, it
# replies with an alternate link that does not require javascript.
# example link in a comment: http://twitter.com/#!/foobar
# example alternative link:  http://m.twitter.com/foobar

import reddit
import time
import re

from exception_handler import ExpHandler

import pprint

r = reddit.Reddit(user_agent='reddit-link-unscripter')
print r
r.login() # credentials are in reddit_api.cfg
print r
    
# this function isn't used yet
# it will handle multiple domains / URL patterns
def process_submission(submission):
    # loop through the list of URL patterns
    if phrase in comment.body:
        True
    # reply with a modified URL if there's a match

#TODO: handle network failures here
def post_comment(parent,comment):
    result = parent.add_comment(comment)
    return result

def persistent_post_comment(parent,comment,retries=3,debug=False):
    while retries >= 0:
        try:
            if debug:
                print "debug: comment: " + comment
            else:
                print "comment: " + comment
                result = post_comment(parent,comment)
        except reddit.errors.RateLimitExceeded as e:
            print "Rate limited for " + str(e.sleep_time) + " seconds, sleeping"
            time.sleep(e.sleep_time)
            continue
        except Exception as e:
            print e.__class__.__name__,':',e
            print "retrying " + str(retries) + " more times"
            retries -= 1
            continue
        break
    return result

commented_count = 0
post_time_mark = 0

# fetch our last comment, which will dictate how far back we go on the first pass
# TODO: get the creation time of the post, not my reply
my_comments = None
try:
    my_comments = list(r.user.get_comments(limit=1))
except:
    #TODO: handle some exceptions here!
    raise

if len(my_comments) > 0:
    if my_comments[0].created_utc > post_time_mark:
        post_time_mark = my_comments[0].created_utc

# fetch new submissions, check them, reply
while True:
    
    submissions = None
    # right now we are just pulling twitter link posts
    submissions = r.get_content("http://www.reddit.com/domain/twitter.com/new.json",100,{'sort':'new'})

    retrieved_count = 0
    new_time_mark = post_time_mark
    print "Starting loop at " + time.strftime("%a, %d %b %Y %H:%M:%S +0000", time.gmtime())
    for s in submissions:
        retrieved_count += 1
        # skip posts older than our previous "newest post" timestamp
        if s.created_utc > post_time_mark:
            new_url = re.sub('(https?://)(?:www.)?(twitter.com/)#!?/(.*)',r'\1m.\2\3',s.url)
            if new_url != s.url:
                comment = 'This [mobile twitter link](' + new_url + ") will work without requiring javascript.\n\nThis comment generated by an automated bot."
                result = persistent_post_comment(s,comment)
                #TODO: handle failures like being banned here
                print "commented on " + s.name
                pprint.pprint(vars(result))
                print "original URL: " + s.url
                print "replaced URL: " + new_url
                commented_count += 1
                if s.created_utc > new_time_mark:
                    print "New time mark, " + str(s.created_utc)
                    new_time_mark = s.created_utc
            else:
                #print "Nothing to do for " + s.name
                pass
            print "sleeping for 5 seconds, interrupt if you must"
            time.sleep(5) 

    print str(retrieved_count) + " submissions considered at " + time.strftime("%a, %d %b %Y %H:%M:%S +0000", time.gmtime())
    print str(commented_count) + " submissions replied to so far this run"

    post_time_mark = new_time_mark
    
    # sleep for 30 seconds between refreshes of the same page request, per the API rules
    # 300 seconds instead, for now, in case the bot malfunctions, 1/10th as many duplicate posts
    print "sleeping"
    time.sleep(300)
